# POP
Preference Optimization for Pretraining, a loss function making use of a type of "self" ORPO during pretraining going beyond cross-entropy for LLM pretraining.
